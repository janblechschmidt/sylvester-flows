{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913a73aa-c63d-4e67-8ed0-239ab7cdb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "\n",
    "import models.VAE as VAE\n",
    "from optimization.training import train, evaluate\n",
    "from utils.load_data import load_dataset, load_static_mnist\n",
    "from utils.plotting import plot_training_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d17eeb3-f646-454c-a969-c6e806bab71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2557d2ce-8b5b-4321-9176-d6451a300331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "    batch_size = 1024\n",
    "    cuda = True\n",
    "    gpu_num = 0\n",
    "    num_flows = 4\n",
    "    flow = \"orthogonal\"\n",
    "    #flow = \"no_flow\"\n",
    "    num_ortho_vecs = 8\n",
    "    dataset = 'mnist'\n",
    "    manual_seed = 1\n",
    "    z_size = 2\n",
    "    learning_rate = 0.0005\n",
    "    epochs = 200\n",
    "    warmup = 100\n",
    "    max_beta = 1.\n",
    "    min_beta = 0.\n",
    "    log_interval = 10\n",
    "    out_dir = 'snapshots'\n",
    "    early_stopping_epochs = 100\n",
    "\n",
    "args=Args()\n",
    "\n",
    "args.model_signature = str(datetime.datetime.now())[0:19].replace(' ', '_')\n",
    "args.model_signature = args.model_signature.replace(':', '_')\n",
    "\n",
    "snapshots_path = os.path.join(args.out_dir, 'vae_' + args.dataset + '_')\n",
    "snap_dir = snapshots_path + args.flow + '_gpunum_' + str(args.gpu_num)\n",
    "\n",
    "if args.flow != 'no_flow':\n",
    "    snap_dir += '_' + 'num_flows_' + str(args.num_flows)\n",
    "if args.flow == 'orthogonal':\n",
    "    snap_dir = snap_dir + '_num_vectors_' + str(args.num_ortho_vecs)\n",
    "elif args.flow == 'householder':\n",
    "    snap_dir = snap_dir + '_num_householder_' + str(args.num_householder)\n",
    "elif args.flow == 'iaf':\n",
    "    snap_dir = snap_dir + '_madehsize_' + str(args.made_h_size)\n",
    "\n",
    "snap_dir = snap_dir + '__' + args.model_signature + '/'\n",
    "\n",
    "args.snap_dir = snap_dir\n",
    "\n",
    "if not os.path.exists(snap_dir):\n",
    "    os.makedirs(snap_dir)\n",
    "\n",
    "if args.manual_seed is None:\n",
    "    args.manual_seed = random.randint(1, 100000)\n",
    "random.seed(args.manual_seed)\n",
    "torch.manual_seed(args.manual_seed)\n",
    "np.random.seed(args.manual_seed)\n",
    "\n",
    "if args.cuda:\n",
    "    # gpu device number\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 0, 'pin_memory': True} if args.cuda else {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97cf598a-247c-4609-90db-0f36ae0d41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python main_experiment.py -d mnist -nf 4 --flow orthogonal --num_ortho_vecs 8 \n",
    "\n",
    "# ==================================================================================================================\n",
    "# LOAD DATA\n",
    "# ==================================================================================================================\n",
    "\n",
    "train_loader, val_loader, test_loader, args = load_dataset(args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "37ddc9b4-f69e-41f7-858c-57f1f1b825ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathe/lvhome10/users/personal/blja/Work/git/sylvester-flows/models/VAE.py:400: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m VAE\u001b[38;5;241m.\u001b[39mIAFVAE(args)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mflow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morthogonal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mVAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOrthogonalSylvesterVAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mflow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhouseholder\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     15\u001b[0m     model \u001b[38;5;241m=\u001b[39m VAE\u001b[38;5;241m.\u001b[39mHouseholderSylvesterVAE(args)\n",
      "File \u001b[0;32m/home/mathe/lvhome10/users/personal/blja/Work/git/sylvester-flows/models/VAE.py:270\u001b[0m, in \u001b[0;36mOrthogonalSylvesterVAE.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_flows \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mnum_flows\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_ortho_vecs \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mnum_ortho_vecs\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_ortho_vecs \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_size) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_ortho_vecs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Orthogonalization parameters\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_ortho_vecs \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_size:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================\n",
    "# SELECT MODEL\n",
    "# ==================================================================================================================\n",
    "# flow parameters and architecture choice are passed on to model through args\n",
    "\n",
    "if args.flow == 'no_flow':\n",
    "    model = VAE.VAE(args)\n",
    "elif args.flow == 'planar':\n",
    "    model = VAE.PlanarVAE(args)\n",
    "elif args.flow == 'iaf':\n",
    "    model = VAE.IAFVAE(args)\n",
    "elif args.flow == 'orthogonal':\n",
    "    model = VAE.OrthogonalSylvesterVAE(args)\n",
    "elif args.flow == 'householder':\n",
    "    model = VAE.HouseholderSylvesterVAE(args)\n",
    "elif args.flow == 'triangular':\n",
    "    model = VAE.TriangularSylvesterVAE(args)\n",
    "else:\n",
    "    raise ValueError('Invalid flow choice')\n",
    "\n",
    "if args.cuda:\n",
    "    print(\"Model on GPU\")\n",
    "    model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8cd41-022f-41ae-b61e-ce32e7638bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adamax(model.parameters(), lr=args.learning_rate, eps=1.e-7)\n",
    "snap_dir = args.snap_dir\n",
    "# ==================================================================================================================\n",
    "# TRAINING\n",
    "# ==================================================================================================================\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# for early stopping\n",
    "best_loss = np.inf\n",
    "best_bpd = np.inf\n",
    "e = 0\n",
    "epoch = 0\n",
    "\n",
    "train_times = []\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "    t_start = time.time()\n",
    "    tr_loss = train(epoch, train_loader, model, optimizer, args)\n",
    "    train_loss.append(tr_loss)\n",
    "    train_times.append(time.time()-t_start)\n",
    "    print('One training epoch took %.2f seconds' % (time.time()-t_start))\n",
    "\n",
    "    v_loss, v_bpd = evaluate(val_loader, model, args, epoch=epoch)\n",
    "\n",
    "    val_loss.append(v_loss)\n",
    "\n",
    "    # early-stopping\n",
    "    if v_loss < best_loss:\n",
    "        e = 0\n",
    "        best_loss = v_loss\n",
    "        if args.input_type != 'binary':\n",
    "            best_bpd = v_bpd\n",
    "        print('->model saved<-')\n",
    "        torch.save(model, args.snap_dir + args.flow + '.model')\n",
    "        # torch.save(model, snap_dir + args.flow + '_' + args.architecture + '.model')\n",
    "\n",
    "    elif (args.early_stopping_epochs > 0) and (epoch >= args.warmup):\n",
    "        e += 1\n",
    "        if e > args.early_stopping_epochs:\n",
    "            break\n",
    "\n",
    "    if args.input_type == 'binary':\n",
    "        print('--> Early stopping: {}/{} (BEST: loss {:.4f})\\n'.format(e, args.early_stopping_epochs, best_loss))\n",
    "\n",
    "    else:\n",
    "        print('--> Early stopping: {}/{} (BEST: loss {:.4f}, bpd {:.4f})\\n'.format(e, args.early_stopping_epochs,\n",
    "                                                                               best_loss, best_bpd))\n",
    "\n",
    "    if math.isnan(v_loss):\n",
    "        raise ValueError('NaN encountered!')\n",
    "\n",
    "train_loss = np.hstack(train_loss)\n",
    "val_loss = np.array(val_loss)\n",
    "\n",
    "plot_training_curve(train_loss, val_loss, fname=args.snap_dir + '/training_curve_%s.pdf' % args.flow)\n",
    "\n",
    "# training time per epoch\n",
    "train_times = np.array(train_times)\n",
    "mean_train_time = np.mean(train_times)\n",
    "std_train_time = np.std(train_times, ddof=1)\n",
    "print('Average train time per epoch: %.2f +/- %.2f' % (mean_train_time, std_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "967e0e72-5259-43f7-ac2b-c8ab264bcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.style.use('default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84416a62-8100-4664-9560-aed24fa3d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "device='cuda'\n",
    "def plot_reconstructed(model, r0=(-5, 5), r1=(-5, 5), n=12):\n",
    "    w = 28\n",
    "    img = np.zeros((n*w, n*w))\n",
    "    for i, y in enumerate(np.linspace(*r1, n)):\n",
    "        for j, x in enumerate(np.linspace(*r0, n)):\n",
    "            z = torch.Tensor([[x, y]]).to(device)\n",
    "            x_hat = model.decode(z)\n",
    "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n",
    "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n",
    "    return img\n",
    "\n",
    "img = plot_reconstructed(model)\n",
    "r0=(-5, 5)\n",
    "r1=(-5, 5)   \n",
    "ax = plt.imshow(img, extent=[*r0, *r1])\n",
    "plt.savefig('tmp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77075c2c-7a10-4ffe-87c0-131ab944ca6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0f39127d10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a239539b-86a1-4d5b-aabd-b3be8c1b44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructed(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "888e71fe-d801-4cf1-8a10-52e679f8b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f39695340>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0,1,3), np.linspace(0,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023fd8a4-7156-4c87-9aeb-44de39c72f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3f19d-0511-472b-afe3-f7576bc2b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xlin = np.linspace(-2, 2, 5)\n",
    "X, Y = np.meshgrid(xlin, xlin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02055aaa-cde3-4f60-beab-d7954f555e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6389a-53c4-42f8-ad85-3a3fa2f0a0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce735f-c30d-4e60-aa90-57dc12425610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996de279-6b9b-40f4-b76b-7eea5cc57314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args, kwargs):\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Sylvester Normalizing flows')\n",
    "    \n",
    "    parser.add_argument('-d', '--dataset', type=str, default='mnist', choices=['mnist', 'freyfaces', 'omniglot', 'caltech'],\n",
    "                        metavar='DATASET',\n",
    "                        help='Dataset choice.')\n",
    "    \n",
    "    parser.add_argument('-freys', '--freyseed', type=int, default=123,\n",
    "                        metavar='FREYSEED',\n",
    "                        help=\"\"\"Seed for shuffling frey face dataset for test split. Ignored for other datasets.\n",
    "                        Results in paper are produced with seeds 123, 321, 231\"\"\")\n",
    "    \n",
    "    parser.add_argument('-nc', '--no_cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    \n",
    "    parser.add_argument('--manual_seed', type=int, help='manual seed, if not given resorts to random seed.')\n",
    "    \n",
    "    parser.add_argument('-li', '--log_interval', type=int, default=10, metavar='LOG_INTERVAL',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    \n",
    "    parser.add_argument('-od', '--out_dir', type=str, default='snapshots', metavar='OUT_DIR',\n",
    "                        help='output directory for model snapshots etc.')\n",
    "    \n",
    "    fp = parser.add_mutually_exclusive_group(required=False)\n",
    "    fp.add_argument('-te', '--testing', action='store_true', dest='testing',\n",
    "                    help='evaluate on test set after training')\n",
    "    fp.add_argument('-va', '--validation', action='store_false', dest='testing',\n",
    "                    help='only evaluate on validation set')\n",
    "    parser.set_defaults(testing=True)\n",
    "    \n",
    "    # optimization settings\n",
    "    parser.add_argument('-e', '--epochs', type=int, default=2000, metavar='EPOCHS',\n",
    "                        help='number of epochs to train (default: 2000)')\n",
    "    parser.add_argument('-es', '--early_stopping_epochs', type=int, default=100, metavar='EARLY_STOPPING',\n",
    "                        help='number of early stopping epochs')\n",
    "    \n",
    "    parser.add_argument('-bs', '--batch_size', type=int, default=100, metavar='BATCH_SIZE',\n",
    "                        help='input batch size for training (default: 100)')\n",
    "    parser.add_argument('-lr', '--learning_rate', type=float, default=0.0005, metavar='LEARNING_RATE',\n",
    "                        help='learning rate')\n",
    "    \n",
    "    parser.add_argument('-w', '--warmup', type=int, default=100, metavar='N',\n",
    "                        help='number of epochs for warm-up. Set to 0 to turn warmup off.')\n",
    "    parser.add_argument('--max_beta', type=float, default=1., metavar='MB',\n",
    "                        help='max beta for warm-up')\n",
    "    parser.add_argument('--min_beta', type=float, default=0.0, metavar='MB',\n",
    "                        help='min beta for warm-up')\n",
    "    parser.add_argument('-f', '--flow', type=str, default='no_flow', choices=['planar', 'iaf', 'householder', 'orthogonal',\n",
    "                                                                              'triangular', 'no_flow'],\n",
    "                        help=\"\"\"Type of flows to use, no flows can also be selected\"\"\")\n",
    "    parser.add_argument('-nf', '--num_flows', type=int, default=4,\n",
    "                        metavar='NUM_FLOWS', help='Number of flow layers, ignored in absence of flows')\n",
    "    parser.add_argument('-nv', '--num_ortho_vecs', type=int, default=8, metavar='NUM_ORTHO_VECS',\n",
    "                        help=\"\"\" For orthogonal flow: How orthogonal vectors per flow do you need.\n",
    "                        Ignored for other flow types.\"\"\")\n",
    "    parser.add_argument('-nh', '--num_householder', type=int, default=8, metavar='NUM_HOUSEHOLDERS',\n",
    "                        help=\"\"\" For Householder Sylvester flow: Number of Householder matrices per flow.\n",
    "                        Ignored for other flow types.\"\"\")\n",
    "    parser.add_argument('-mhs', '--made_h_size', type=int, default=320,\n",
    "                        metavar='MADEHSIZE', help='Width of mades for iaf. Ignored for all other flows.')\n",
    "    parser.add_argument('--z_size', type=int, default=64, metavar='ZSIZE',\n",
    "                        help='how many stochastic hidden units')\n",
    "    # gpu/cpu\n",
    "    parser.add_argument('--gpu_num', type=int, default=0, metavar='GPU', help='choose GPU to run on.')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    print('\\nMODEL SETTINGS: \\n', args, '\\n')\n",
    "    print(\"Random Seed: \", args.manual_seed)\n",
    "\n",
    "    # ==================================================================================================================\n",
    "    # SNAPSHOTS\n",
    "    # ==================================================================================================================\n",
    "    \n",
    "\n",
    "    # SAVING\n",
    "    torch.save(args, snap_dir + args.flow + '.config')\n",
    "\n",
    "\n",
    "\n",
    "    # ==================================================================================================================\n",
    "    # TRAINING\n",
    "    # ==================================================================================================================\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    # for early stopping\n",
    "    best_loss = np.inf\n",
    "    best_bpd = np.inf\n",
    "    e = 0\n",
    "    epoch = 0\n",
    "\n",
    "    train_times = []\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "        t_start = time.time()\n",
    "        tr_loss = train(epoch, train_loader, model, optimizer, args)\n",
    "        train_loss.append(tr_loss)\n",
    "        train_times.append(time.time()-t_start)\n",
    "        print('One training epoch took %.2f seconds' % (time.time()-t_start))\n",
    "\n",
    "        v_loss, v_bpd = evaluate(val_loader, model, args, epoch=epoch)\n",
    "\n",
    "        val_loss.append(v_loss)\n",
    "\n",
    "        # early-stopping\n",
    "        if v_loss < best_loss:\n",
    "            e = 0\n",
    "            best_loss = v_loss\n",
    "            if args.input_type != 'binary':\n",
    "                best_bpd = v_bpd\n",
    "            print('->model saved<-')\n",
    "            torch.save(model, snap_dir + args.flow + '.model')\n",
    "            # torch.save(model, snap_dir + args.flow + '_' + args.architecture + '.model')\n",
    "\n",
    "        elif (args.early_stopping_epochs > 0) and (epoch >= args.warmup):\n",
    "            e += 1\n",
    "            if e > args.early_stopping_epochs:\n",
    "                break\n",
    "\n",
    "        if args.input_type == 'binary':\n",
    "            print('--> Early stopping: {}/{} (BEST: loss {:.4f})\\n'.format(e, args.early_stopping_epochs, best_loss))\n",
    "\n",
    "        else:\n",
    "            print('--> Early stopping: {}/{} (BEST: loss {:.4f}, bpd {:.4f})\\n'.format(e, args.early_stopping_epochs,\n",
    "                                                                                   best_loss, best_bpd))\n",
    "\n",
    "        if math.isnan(v_loss):\n",
    "            raise ValueError('NaN encountered!')\n",
    "\n",
    "    train_loss = np.hstack(train_loss)\n",
    "    val_loss = np.array(val_loss)\n",
    "\n",
    "    plot_training_curve(train_loss, val_loss, fname=args.snap_dir + '/training_curve_%s.pdf' % args.flow)\n",
    "\n",
    "    # training time per epoch\n",
    "    train_times = np.array(train_times)\n",
    "    mean_train_time = np.mean(train_times)\n",
    "    std_train_time = np.std(train_times, ddof=1)\n",
    "    print('Average train time per epoch: %.2f +/- %.2f' % (mean_train_time, std_train_time))\n",
    "\n",
    "    # ==================================================================================================================\n",
    "    # EVALUATION\n",
    "    # ==================================================================================================================\n",
    "\n",
    "    test_score_file = snap_dir + 'test_scores.txt'\n",
    "\n",
    "    with open('experiment_log.txt', 'a') as ff:\n",
    "        print(args, file=ff)\n",
    "        print('Stopped after %d epochs' % epoch, file=ff)\n",
    "        print('Average train time per epoch: %.2f +/- %.2f' % (mean_train_time, std_train_time), file=ff)\n",
    "\n",
    "    final_model = torch.load(snap_dir + args.flow + '.model')\n",
    "\n",
    "    if args.testing:\n",
    "        validation_loss, validation_bpd = evaluate(val_loader, final_model, args)\n",
    "        test_loss, test_bpd = evaluate(test_loader, final_model, args, testing=True)\n",
    "\n",
    "        with open('experiment_log.txt', 'a') as ff:\n",
    "            print('FINAL EVALUATION ON VALIDATION SET\\n'\n",
    "                  'ELBO (VAL): {:.4f}\\n'.format(validation_loss), file=ff)\n",
    "            print('FINAL EVALUATION ON TEST SET\\n'\n",
    "                  'NLL (TEST): {:.4f}\\n'.format(test_loss), file=ff)\n",
    "            if args.input_type != 'binary':\n",
    "                print('FINAL EVALUATION ON VALIDATION SET\\n'\n",
    "                      'ELBO (VAL) BPD : {:.4f}\\n'.format(validation_bpd), file=ff)\n",
    "                print('FINAL EVALUATION ON TEST SET\\n'\n",
    "                      'NLL (TEST) BPD: {:.4f}\\n'.format(test_bpd), file=ff)\n",
    "\n",
    "\n",
    "    else:\n",
    "        validation_loss, validation_bpd = evaluate(val_loader, final_model, args)\n",
    "        # save the test score in case you want to look it up later.\n",
    "        _, _ = evaluate(test_loader, final_model, args, testing=True, file=test_score_file)\n",
    "\n",
    "        with open('experiment_log.txt', 'a') as ff:\n",
    "            print('FINAL EVALUATION ON VALIDATION SET\\n'\n",
    "                  'ELBO (VALIDATION): {:.4f}\\n'.format(validation_loss), file=ff)\n",
    "            if args.input_type != 'binary':\n",
    "                print('FINAL EVALUATION ON VALIDATION SET\\n'\n",
    "                      'ELBO (VAL) BPD : {:.4f}\\n'.format(validation_bpd), file=ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696a8b0-9995-4f96-881f-5e6c1098f803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax (shared)",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
